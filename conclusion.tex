\chapter*{Conclusion et perspectives}
\mtcaddchapter[Conclusion et perspectives]
\label{chap:conclusion}
La réduction de la visibilité horizontale est un facteur important d'accidents dans les divers secteurs de transport, en particulier l'aéronautique. Elle peut générer des dégâts financiers et humain considérables. D'où la prévision de la visibilité sera  d’un  grand  apport  pour  les  prévisionnistes météorologiques afin de minimiser et réduire les perturbations touchant les secteurs aérien, maritime et routier. Dans la littérature, diverses plateformes et algorithmes open-source ont été utilisés pour l’estimation de la visibilité selon diverses approches  (classification  et  régression). Ainsi, les performances des modèles développés différent d’une étude à une autre. L'objectif de ce stage est d'étudier la sensibilité de la performance des modèles développés à la plateforme et l'algorithme Datamining utilisés.\\


Afin d'atteindre notre objectif, certaines méthodes de Datamining sont appliquées aux sorties du modèle de prévision numérique du temps AROME, sous différentes plateformes open-source (\textit{Scikit-learn}, \textit{H2O}, \textit{WEKA}, \textit{Tensorflow} et \textit{Keras}) pour estimer la visibilité horizontale. Ainsi la base de données utilisée couvre 3 années de données horaires, répartie en 70\% pour l’apprentissage et 30\% pour le test afin d'évaluer la performance des algorithmes développés. Cet échantillonnage a été effectué de telle façon de garantir la représentativité des mois, des heures et des diverses classes de visibilités pour toutes les stations synoptiques utilisés dans les deux fichiers de données (test et apprentissage). Du côté outil de développement, nous avons opté pour une approche d'estimation par régression pour l'estimation de la visibilité horizontale. Ainsi, deux familles d'algorithmes du Datamining purement distinctes ont été employés: méthodes ensembliste incluant \textit{Random Forest}, \textit{Gradient Boosting Machine} et \textit{eXtreme Gradient Boosting} et l'apprentissage profond \textit{Deep Learning}.\\


Le développement et la modélisation des algorithmes Datamining a consisté dans un premier temps en l'utilisation de la configuration par défaut, puis dans l'étape suivante, nous avons réglé les hyper-paramètres en utilisant les deux techniques Grid Search et Random Search pour chaque algorithme Datamining utilisé dans cette étude sous divers plateformes open source. Ceci nous a permis d’obtenir le meilleur modèle pour un algorithme avec les hyperparamètres optimums.\\


L’analyse des résultats obtenus pour les déférents algorithmes utilisés sous les diverses plateformes, montre que la performance des modèles ensemblistes est la meilleure quelque soit la plateforme utilisée sauf pour \textit{Keras} où seul le \textit{Deep Learning} a été utilisé (plateforme considérée alors hors comparaison).  Ainsi, l’algorithme \textit{Random Forest} s’affiche comme meilleur estimateur de la visibilité après réglage des hyperparamètres pour les plateformes \textit{WEKA} et \textit{Scikit-learn}. Cependant, \textit{Gradient boosting machine} s’est distingué comme meilleur estimateur pour la plateforme \textit{H2O}. Les ordres de grandeurs des erreurs enregistrées sont similaires entre les diverses plateformes. Ainsi, on constate des erreurs quadratiques moyennes de 1933 m, 1942 m et 1945 m respectivement pour \textit{Gradient Boosting} sous \textit{H2O}, \textit{Random Forest} pour\textit{ Scikit-learn} et \textit{WEKA}. De même pour l’erreur absolue moyenne qui prend les valeurs suivantes 1199 m, 1221 m et 1232 m pour les mêmes algorithmes et plateformes.\\

Lors de la phase d'analyse croisée, nous  avons intégré  les hyperparamètres optimums obtenus soit par Grid search soit par Random search pour une plateforme donnée, dans le même algorithme mais pour une autre plateforme. Cette  approche  a  été  abordée  du  fait  que  lors  l’optimisation  des hyperparamètres, Grid Search permet de tester une série de paramètres et de comparer les performances pour en déduire le meilleur paramétrage. Or, Random Search est  une  technique  dans  laquelle  des  combinaisons  aléatoires  des hyperparamètres sont utilisées pour trouver la meilleure solution d’un modèle développé. Ainsi, il se peut que les hyperparamètres trouvés pour une plateforme donnée  ne  soient  pas  inclus  dans  la  fourchette  adoptée  pour  une  autre plateforme lors de la phase d’optimisation. On constate ainsi que les statistiques de la performance du modèle régresseur à base de \textit{Random Forest} et \textit{Gradient Boosting Machine} sont similaires. Pour \textit{eXtreme Gradient Boosting}, on constate que les statistiques de la performance du modèle régresseur se dégradent sous \textit{H2O}. Ainsi, on constate une dégradation de 222 m
en termes d’erreur quadratiques moyenne RMSE et un écart de 110 m en termes d’erreur absolue moyenne MAE. Pour le \textit{Deep Learning}, on a constaté que le changement de la plateforme impacte la performance du modèle régresseur pour les mêmes hyperparamètres.\\

L’analyse  comparative  par plateforme et par algorithmes  de l'importance des paramètres météorologiques a permis d'identifier ceux qui ont plus de poids lors l’estimation de la visibilité à partir des  prévisions  du  modèle  AROME. On constate ainsi que l’implémentation des algorithmes sous les plateformes utilisées donne l’importance pour diverses variables lors du développement des algorithmes Datamining. Ainsi, on retrouve souvent la position géographique
(latitude, longitude et Altitude) et ceci peut être justifié par le fait qu’on est en train d’étudier un problème de régression à caractère spatial. En fait, on cherche à estimer la visibilité sur un large domaine. Ensuite, on trouve des paramètres importants et qui impactent largement l’occurrence de la visibilité réduite à savoir les température et l’humidité à 2m ainsi que la pression au niveau de la surface et le rayonnement.\\

Les résultats de cette étude sont encourageants cependant il est utile de rappeler certaines limites de cette dernière et de citer certaines perspectives qui restent à explorer. Notre étude s’est focalisée sur une durée d'étude de 3 ans, ainsi il serait intéressant d’augmenter la durée de notre étude, aussi il sera d'un grand apport d'évaluer la sensibilité de la performance des modèles développés aux plateformes et algorithmes Datamining pour un cas de classification. D'autre part, il serait judicieux d'évaluer objectivement les plateformes à la base des indices appropriés. Enfin il serait judicieux d’évaluer l’apport d’autres plateformes open source.